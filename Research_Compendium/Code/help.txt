Evaluation:
------------------------------------------------------------------------------------------------
test_classifier.py tests MobileNetV2 model. Ensure --model is pointing to the correct tensorflow/tensorflow lite model and --data_dir is at the right test_images

test_combined_v5.py tests the two stage pipeline for the version tailored for Raspberry Pi 5. Ensure both model are pointing to the right path and test image as well.

test_combined_v8.py tests the two stage pipeline from the Workstation A. Ensure both model are pointing to the right path and test image as well.

test_dynamic_pt.py tests the dynamic model with pytorch framework. Ensure model are pointing to the right path and test video.

test_dynamic_tflite.py tests the tensorflow lite model with tflite framework. Ensure model are pointing to the right path and test video.


Inference:
------------------------------------------------------------------------------------------------
asl_intepreter_YOLOv8n.py is the version transformed straight from Workstation A. It does not perform well in terms of resource usage on the Raspberry Pi 5.
asl_intepreter_YOLOv5n.py is the final version tailored for Raspberry Pi 5.
dynamic_interpreter.py is the tensorflow version of dynamic

For asl_intepreter_YOLOv8n.py --model_path needs to be pointing to the correct classifier
			      --yolo_weights needs to be pointing to the correct yolo model
For asl_intepreter_YOLOv5n.py --det_tflite needs to be pointing to the correct classifier
			      --cls_tflite needs to be pointing to the correct yolo model
For both script --labels needs to be labels_classifier.json if running ASL+BSL

Inside the script line 50 needs to be pointing to the lsa64_fast_20250917_203048_meta.tflite model, line 51 label needs to be changed to lsa64_fast_20250917_203048_meta.json


These models can be found inside Model folder.


Models:
------------------------------------------------------------------------------------------------
labels_classifier.json contains the label for model_ASL+BSL.h5 and model_ASL+BSL.tflite

model_ASL.h5 and model_ASL.tflite does not need a label.

lsa64_fast_20250917_203048_meta.json is the label for lsa64_fast_20250917_203048_meta.pt and lsa64_fast_20250917_203048_meta.tflite

v5n_100epoch_img416.tflite is the YOLOv5n model

v8n_100epoch_img416.pt is the YOLOv8n model

YOLO_classify contains the failed model of YOLO tracking and classification

Training:
------------------------------------------------------------------------------------------------
MobileNetV2 contains the training code for MobileNetV2. Ensure --data_root is pointing to the correct folder path when training.

YOLOv8n training is done by installing Ultralytics and calling "yolo task=detect mode=train model=yolov8n.pt data=dataset/data.yaml epochs=100 imgsz=416 device=0" Ensure dataset is pointing to the right path

Jerry add your stuff here for LSA64 and WLASL

utils:
down_sample.py
------------------------------------------------------------------------------------------------

This script samples images from the ASL alphabet dataset to create a smaller subset for training or testing.

- It loops through all class folders (Aâ€“Z, del, space, nothing).
- Copies every Nth image (set by `sample_interval`) into a new output folder.
- Keeps the original folder structure.
- Only .png, .jpg, and .jpeg files are copied.
- File metadata is preserved.


labeller_yolo.py
------------------
This script provides a manual labeling interface for images to generate YOLO-format `.txt` annotation files.

- Opens each image and allows the user to draw a bounding box.
- Press Enter/Space to finish drawing.
- Press:
  - y = save box
  - r = redraw
  - s = skip
  - q = quit

Labels are saved in `labels_yolo/` and corresponding images in `labeled_images/`. The bounding boxes are normalized for YOLO training.


take_photo.py
--------------------
This script captures labeled photos directly from a webcam.

- Press 's' to take a photo (with optional delay).
- Press 'q' to quit.
- Files are saved as <base_name>_<index>.jpg in the `captures/` folder.
- Automatically continues indexing from the last saved file.

hand_extract_for_yolo.py
----------------------------
This script crops hands from images based on YOLO label files.

- Reads images and corresponding `.txt` labels.
- Supports YOLO bounding boxes and polygon annotations.
- Crops the hand region and saves it to `cropped_hands/`.
- Skips missing or unreadable files automatically.

labeller_yolo.py
-------------------
This is a manual image labeling tool similar to the YOLO version.

- Opens each image for bounding box selection.
- Draw ROI, then press y/r/s/q to save, redraw, skip, or quit.
- Labels are saved in YOLO text format, and labeled images are copied to `labeled_images/`.

Useful for quickly generating simple bounding boxes for training.


