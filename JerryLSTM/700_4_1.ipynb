{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMPLIFIED CONFIGURATION FOR LIMITED DATA:\n",
      "  Strategy: Minimal model + Strong regularization\n",
      "  Classes: 20 (reduced)\n",
      "  Sequence length: 96\n",
      "  Model: 32 LSTM -> 64 Dense\n",
      "  Dropout: LSTM 0.5, Dense 0.7\n",
      "  L2 reg: 0.001\n",
      "\n",
      "Simplified configuration initialized!\n",
      "FOCUS: Prevent class collapse with minimal complexity\n"
     ]
    }
   ],
   "source": [
    "# @title 1: Simplified Setup for Limited Data\n",
    "# Core imports and setup\n",
    "import os, gc, json, logging, warnings, random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "def set_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seeds(SEED)\n",
    "\n",
    "# GPU setup\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPU setup complete: {len(gpus)} GPU(s)\")\n",
    "    except Exception as e:\n",
    "        print(f\"GPU setup warning: {e}\")\n",
    "\n",
    "# SIMPLIFIED Configuration for limited data\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # Dataset paths\n",
    "        possible_paths = [\n",
    "            \"/kaggle/input/wlasl-processed/\",\n",
    "            \"/root/.cache/kagglehub/datasets/risangbaskoro/wlasl-processed/versions/5\",\n",
    "            \"/root/.cache/kagglehub/datasets/risangbaskoro/wlasl-processed/versions/4\",\n",
    "            \"/content/wlasl-processed/\",\n",
    "            \"./risangbaskoro/wlasl-processed/versions/5\"\n",
    "        ]\n",
    "\n",
    "        self.dataset_base_path = None\n",
    "        for path in possible_paths:\n",
    "            if os.path.exists(path):\n",
    "                self.dataset_base_path = path\n",
    "                break\n",
    "\n",
    "        if self.dataset_base_path is None:\n",
    "            self.dataset_base_path = \"/kaggle/input/wlasl-processed/\"\n",
    "\n",
    "        # REDUCED complexity for limited data\n",
    "        self.target_classes = 20                 # Start with fewer classes\n",
    "        self.min_videos_per_class = 8          # Keep minimum\n",
    "        self.preferred_videos_per_class = 16   # Reduce target\n",
    "        self.max_videos_per_class = 20         # Increase cap slightly\n",
    "        self.allow_class_imbalance = True\n",
    "        self.max_imbalance_ratio = 2.0\n",
    "\n",
    "        # SHORTER sequences for faster training\n",
    "        self.sequence_length = 96              # Reduced back to 32\n",
    "        self.batch_size = 4                     # Smaller batches\n",
    "        self.num_epochs = 100                  # Fewer epochs\n",
    "        self.learning_rate = 0.002             # Higher learning rate\n",
    "        self.validation_split = 0.2            # More validation for better estimates\n",
    "\n",
    "        # MUCH SMALLER model architecture\n",
    "        self.lstm_units = 32                   # Single LSTM layer\n",
    "        self.dense_units = 64                  # Single dense layer\n",
    "\n",
    "        # STRONG regularization for limited data\n",
    "        self.lstm_dropout = 0.5\n",
    "        self.lstm_recurrent_dropout = 0.3\n",
    "        self.dense_dropout = 0.7               # Very high dropout\n",
    "        self.l2_reg = 0.001                    # Strong L2 regularization\n",
    "\n",
    "        # SIMPLE loss function\n",
    "        self.use_focal_loss = False            # Standard loss first\n",
    "        self.min_detection_confidence = 0.5   # Higher confidence threshold\n",
    "        self.use_class_weights = True\n",
    "\n",
    "        # AGGRESSIVE early stopping\n",
    "        self.early_stopping_patience = 15\n",
    "        self.lr_reduction_patience = 8\n",
    "        self.lr_reduction_factor = 0.3\n",
    "        self.min_lr = 1e-6\n",
    "\n",
    "        # MINIMAL augmentation to avoid overfitting\n",
    "        self.use_data_augmentation = False\n",
    "        self.gradient_clip_norm = 0.5\n",
    "\n",
    "        self.model_name = f\"simple_asl_{self.target_classes}_classes\"\n",
    "\n",
    "        print(f\"SIMPLIFIED CONFIGURATION FOR LIMITED DATA:\")\n",
    "        print(f\"  Strategy: Minimal model + Strong regularization\")\n",
    "        print(f\"  Classes: {self.target_classes} (reduced)\")\n",
    "        print(f\"  Sequence length: {self.sequence_length}\")\n",
    "        print(f\"  Model: {self.lstm_units} LSTM -> {self.dense_units} Dense\")\n",
    "        print(f\"  Dropout: LSTM {self.lstm_dropout}, Dense {self.dense_dropout}\")\n",
    "        print(f\"  L2 reg: {self.l2_reg}\")\n",
    "\n",
    "# Create configuration instance\n",
    "config = Config()\n",
    "print(\"\\nSimplified configuration initialized!\")\n",
    "print(\"FOCUS: Prevent class collapse with minimal complexity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2: Dataset Download\n",
    "# Download dataset from Kaggle\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "# path = kagglehub.dataset_download(\"risangbaskoro/wlasl-processed\")\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MediaPipe successfully imported\n",
      "Simple feature extraction ready!\n",
      "SIMPLIFICATIONS:\n",
      "  - Higher confidence threshold (0.5)\n",
      "  - Basic preprocessing only\n",
      "  - Simple quality scoring\n",
      "  - No complex augmentation\n",
      "  - Focus on consistent, high-quality features\n"
     ]
    }
   ],
   "source": [
    "# @title 3: Simplified Feature Extraction for Limited Data\n",
    "import glob, cv2\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "try:\n",
    "    import mediapipe as mp\n",
    "    MEDIAPIPE_AVAILABLE = True\n",
    "    print(\"MediaPipe successfully imported\")\n",
    "except Exception as e:\n",
    "    MEDIAPIPE_AVAILABLE = False\n",
    "    print(f\"MediaPipe not available: {e}\")\n",
    "\n",
    "class SimpleFeatureExtractor:\n",
    "    def __init__(self, min_confidence=0.5):\n",
    "        self.total_features = 126  # 2 hands * 21 landmarks * 3 coordinates\n",
    "        self.min_confidence = min_confidence\n",
    "\n",
    "        if MEDIAPIPE_AVAILABLE:\n",
    "            try:\n",
    "                self.mp_hands = mp.solutions.hands\n",
    "                self.hands = self.mp_hands.Hands(\n",
    "                    static_image_mode=False,\n",
    "                    max_num_hands=2,\n",
    "                    model_complexity=0,  # Lowest complexity for speed\n",
    "                    min_detection_confidence=self.min_confidence,\n",
    "                    min_tracking_confidence=0.7\n",
    "                )\n",
    "                self.use_mediapipe = True\n",
    "                print(f\"Simple MediaPipe extractor ready (confidence={self.min_confidence})\")\n",
    "            except Exception as e:\n",
    "                print(f\"MediaPipe setup failed: {e}\")\n",
    "                self.use_mediapipe = False\n",
    "        else:\n",
    "            self.use_mediapipe = False\n",
    "\n",
    "    def extract_features(self, frame):\n",
    "        if not self.use_mediapipe:\n",
    "            return np.zeros(self.total_features, dtype=np.float32)\n",
    "\n",
    "        try:\n",
    "            # Basic preprocessing only\n",
    "            height, width = frame.shape[:2]\n",
    "            if height != 480 or width != 640:\n",
    "                frame = cv2.resize(frame, (640, 480))\n",
    "            \n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = self.hands.process(rgb)\n",
    "\n",
    "            features = np.zeros(self.total_features, dtype=np.float32)\n",
    "\n",
    "            if results.multi_hand_landmarks and results.multi_handedness:\n",
    "                # Simple hand sorting\n",
    "                hand_data = []\n",
    "                for i, (hand_landmarks, handedness) in enumerate(zip(results.multi_hand_landmarks, results.multi_handedness)):\n",
    "                    if i >= 2:\n",
    "                        break\n",
    "\n",
    "                    is_right_hand = handedness.classification[0].label == 'Right'\n",
    "                    confidence = handedness.classification[0].score\n",
    "                    \n",
    "                    hand_coords = []\n",
    "                    for landmark in hand_landmarks.landmark:\n",
    "                        hand_coords.extend([landmark.x, landmark.y, landmark.z])\n",
    "\n",
    "                    hand_data.append((is_right_hand, hand_coords, confidence))\n",
    "\n",
    "                # Sort by confidence and handedness\n",
    "                hand_data.sort(key=lambda x: (-x[2], not x[0]))\n",
    "\n",
    "                for i, (_, hand_coords, _) in enumerate(hand_data[:2]):\n",
    "                    start_idx = i * 63\n",
    "                    end_idx = start_idx + 63\n",
    "                    features[start_idx:end_idx] = hand_coords\n",
    "\n",
    "            return features\n",
    "\n",
    "        except Exception as e:\n",
    "            return np.zeros(self.total_features, dtype=np.float32)\n",
    "\n",
    "def extract_video_features_simple(video_path, sequence_length=32, min_confidence=0.5):\n",
    "    \"\"\"Simplified feature extraction focusing on quality over quantity\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return None\n",
    "\n",
    "    extractor = SimpleFeatureExtractor(min_confidence=min_confidence)\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Sample frames evenly\n",
    "    if total_frames > sequence_length:\n",
    "        frame_indices = np.linspace(0, total_frames-1, sequence_length*2, dtype=int)\n",
    "    else:\n",
    "        frame_indices = list(range(0, total_frames))\n",
    "\n",
    "    valid_features = []\n",
    "\n",
    "    for frame_idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        feat = extractor.extract_features(frame)\n",
    "\n",
    "        # Simple quality check\n",
    "        non_zero_count = np.count_nonzero(feat)\n",
    "        non_zero_ratio = non_zero_count / feat.size\n",
    "\n",
    "        if non_zero_ratio > 0.1:  # At least 10% non-zero\n",
    "            valid_features.append(feat)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(valid_features) < 8:  # Need minimum frames\n",
    "        return None\n",
    "\n",
    "    # Take best frames by quality\n",
    "    if len(valid_features) > sequence_length:\n",
    "        # Simple quality scoring\n",
    "        quality_scores = []\n",
    "        for feat in valid_features:\n",
    "            non_zero_ratio = np.count_nonzero(feat) / feat.size\n",
    "            feature_var = np.var(feat[feat != 0]) if np.any(feat != 0) else 0\n",
    "            quality_scores.append(non_zero_ratio + feature_var * 100)\n",
    "        \n",
    "        # Select top quality frames\n",
    "        best_indices = np.argsort(quality_scores)[-sequence_length:]\n",
    "        valid_features = [valid_features[i] for i in sorted(best_indices)]\n",
    "\n",
    "    # Convert to array\n",
    "    features_array = np.array(valid_features, dtype=np.float32)\n",
    "\n",
    "    # Pad or truncate to exact length\n",
    "    if len(features_array) < sequence_length:\n",
    "        # Simple repetition padding\n",
    "        needed = sequence_length - len(features_array)\n",
    "        if len(features_array) > 0:\n",
    "            # Repeat last frame\n",
    "            padding = np.tile(features_array[-1:], (needed, 1))\n",
    "            features_array = np.vstack([features_array, padding])\n",
    "        else:\n",
    "            return None\n",
    "    elif len(features_array) > sequence_length:\n",
    "        features_array = features_array[:sequence_length]\n",
    "\n",
    "    return features_array\n",
    "\n",
    "# Set the main function\n",
    "extract_video_features = extract_video_features_simple\n",
    "\n",
    "print(\"Simple feature extraction ready!\")\n",
    "print(\"SIMPLIFICATIONS:\")\n",
    "print(\"  - Higher confidence threshold (0.5)\")\n",
    "print(\"  - Basic preprocessing only\")\n",
    "print(\"  - Simple quality scoring\")\n",
    "print(\"  - No complex augmentation\")\n",
    "print(\"  - Focus on consistent, high-quality features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal model architecture ready!\n",
      "FEATURES:\n",
      "  - Single LSTM layer (32 units)\n",
      "  - Single dense layer (64 units)\n",
      "  - Heavy dropout (0.7 on dense layer)\n",
      "  - Strong L2 regularization\n",
      "  - Batch normalization for stability\n",
      "  - ~3K parameters total (vs 100K+ before)\n"
     ]
    }
   ],
   "source": [
    "# @title 4: Minimal Model Architecture for Limited Data\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def create_minimal_model(config, num_classes):\n",
    "    \"\"\"Create minimal model to prevent overfitting with limited data\"\"\"\n",
    "    tf.keras.backend.clear_session()\n",
    "    set_seeds(SEED)\n",
    "\n",
    "    print(f\"Building MINIMAL model for {num_classes} classes...\")\n",
    "    print(f\"   Strategy: Minimal parameters to prevent overfitting\")\n",
    "    print(f\"   LSTM: {config.lstm_units} units\")\n",
    "    print(f\"   Dense: {config.dense_units} units\")\n",
    "    print(f\"   Heavy regularization applied\")\n",
    "\n",
    "    inputs = Input(shape=(config.sequence_length, 126), dtype='float32', name='input')\n",
    "\n",
    "    # Single LSTM layer with strong regularization\n",
    "    x = LSTM(config.lstm_units, \n",
    "             return_sequences=False,  # Don't return sequences - reduce parameters\n",
    "             dropout=config.lstm_dropout,\n",
    "             recurrent_dropout=config.lstm_recurrent_dropout,\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(config.l2_reg),\n",
    "             recurrent_regularizer=tf.keras.regularizers.l2(config.l2_reg),\n",
    "             name='lstm_layer')(inputs)\n",
    "\n",
    "    # Batch normalization for stability\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    \n",
    "    # Single dense layer with heavy dropout\n",
    "    x = Dense(config.dense_units, \n",
    "              activation='relu',\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(config.l2_reg),\n",
    "              name='dense_layer')(x)\n",
    "    \n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = Dropout(config.dense_dropout, name='heavy_dropout')(x)\n",
    "\n",
    "    # Output layer - no regularization on final layer\n",
    "    outputs = Dense(num_classes, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name=f'Minimal_ASL_Model_{num_classes}_classes')\n",
    "    return model\n",
    "\n",
    "def plot_simple_results(history, model_name):\n",
    "    \"\"\"Simple plotting for limited data results\"\"\"\n",
    "    try:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "        # Loss plot\n",
    "        train_loss = history.history['loss']\n",
    "        val_loss = history.history.get('val_loss', [])\n",
    "\n",
    "        axes[0].plot(train_loss, label='Training Loss', linewidth=2)\n",
    "        if val_loss:\n",
    "            axes[0].plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "            \n",
    "            # Mark best validation loss\n",
    "            best_val_idx = np.argmin(val_loss)\n",
    "            best_val_loss = val_loss[best_val_idx]\n",
    "            axes[0].plot(best_val_idx, best_val_loss, 'ro', markersize=8,\n",
    "                        label=f'Best Val: {best_val_loss:.3f}')\n",
    "\n",
    "        axes[0].set_title('Training Loss')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "        # Accuracy plot\n",
    "        train_acc = history.history['accuracy']\n",
    "        val_acc = history.history.get('val_accuracy', [])\n",
    "\n",
    "        axes[1].plot(train_acc, label='Training Accuracy', linewidth=2)\n",
    "        if val_acc:\n",
    "            axes[1].plot(val_acc, label='Validation Accuracy', linewidth=2)\n",
    "\n",
    "            # Mark best validation accuracy\n",
    "            best_val_idx = np.argmax(val_acc)\n",
    "            best_val_acc = val_acc[best_val_idx]\n",
    "            axes[1].plot(best_val_idx, best_val_acc, 'ro', markersize=8,\n",
    "                        label=f'Best Val: {best_val_acc:.3f}')\n",
    "\n",
    "        # Add random baseline\n",
    "        random_acc = 1.0 / 5  # Assuming 5 classes\n",
    "        axes[1].axhline(y=random_acc, color='gray', linestyle='--', alpha=0.7, \n",
    "                       label=f'Random ({random_acc:.1%})')\n",
    "\n",
    "        axes[1].set_title('Model Accuracy')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Accuracy')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Simple analysis\n",
    "        if val_acc and train_acc:\n",
    "            best_val_acc = max(val_acc)\n",
    "            best_epoch = np.argmax(val_acc) + 1\n",
    "            final_train_acc = train_acc[-1]\n",
    "            final_val_acc = val_acc[-1]\n",
    "            final_gap = final_train_acc - final_val_acc\n",
    "\n",
    "            print(f\"\\nSIMPLE MODEL ANALYSIS:\")\n",
    "            print(f\"Best validation accuracy: {best_val_acc:.4f} (epoch {best_epoch})\")\n",
    "            print(f\"Final train/val accuracy: {final_train_acc:.4f}/{final_val_acc:.4f}\")\n",
    "            print(f\"Overfitting gap: {final_gap:.4f}\")\n",
    "\n",
    "            if final_gap < 0.1:\n",
    "                print(\"OVERFITTING: Minimal - good generalization\")\n",
    "            elif final_gap < 0.2:\n",
    "                print(\"OVERFITTING: Low - acceptable\")\n",
    "            else:\n",
    "                print(\"OVERFITTING: High - need more regularization\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Plotting error: {e}\")\n",
    "\n",
    "# Set the functions to use\n",
    "create_model = create_minimal_model\n",
    "plot_training_results = plot_simple_results\n",
    "\n",
    "print(\"Minimal model architecture ready!\")\n",
    "print(\"FEATURES:\")\n",
    "print(\"  - Single LSTM layer (32 units)\")\n",
    "print(\"  - Single dense layer (64 units)\")\n",
    "print(\"  - Heavy dropout (0.7 on dense layer)\")\n",
    "print(\"  - Strong L2 regularization\")\n",
    "print(\"  - Batch normalization for stability\")\n",
    "print(\"  - ~3K parameters total (vs 100K+ before)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified dataset loader ready!\n",
      "SIMPLIFICATIONS:\n",
      "  - Stricter quality control (50KB+ files, 10+ frames)\n",
      "  - Fewer classes (5) for focused learning\n",
      "  - Balanced allocation per class\n",
      "  - Focus on best available classes\n",
      "  - Quality over quantity approach\n"
     ]
    }
   ],
   "source": [
    "# @title 5: Simplified Dataset Loader for Limited Data\n",
    "def load_simple_dataset(config):\n",
    "    \"\"\"Load dataset with focus on quality over quantity for limited data\"\"\"\n",
    "\n",
    "    print(f\"Loading SIMPLIFIED dataset from: {config.dataset_base_path}\")\n",
    "    print(f\"Strategy: Quality over quantity - fewer classes, better data\")\n",
    "    print(f\"Target: {config.target_classes} classes with {config.min_videos_per_class}+ videos each\")\n",
    "\n",
    "    # Find JSON file\n",
    "    json_files = [\n",
    "        os.path.join(config.dataset_base_path, \"WLASL_v0.3.json\"),\n",
    "        os.path.join(config.dataset_base_path, \"wlasl_v0.3.json\"),\n",
    "        os.path.join(config.dataset_base_path, \"WLASL.json\")\n",
    "    ]\n",
    "\n",
    "    json_path = None\n",
    "    for json_file in json_files:\n",
    "        if os.path.exists(json_file):\n",
    "            json_path = json_file\n",
    "            break\n",
    "\n",
    "    if json_path is None:\n",
    "        print(\"ERROR: WLASL JSON file not found!\")\n",
    "        return [], []\n",
    "\n",
    "    # Find video directory\n",
    "    video_dirs = [\n",
    "        os.path.join(config.dataset_base_path, \"videos\"),\n",
    "        os.path.join(config.dataset_base_path, \"WLASL_videos\"),\n",
    "        config.dataset_base_path\n",
    "    ]\n",
    "\n",
    "    video_dir = None\n",
    "    for vdir in video_dirs:\n",
    "        if os.path.exists(vdir):\n",
    "            mp4_files = [f for f in os.listdir(vdir) if f.endswith('.mp4')]\n",
    "            if len(mp4_files) > 100:\n",
    "                video_dir = vdir\n",
    "                break\n",
    "\n",
    "    if video_dir is None:\n",
    "        print(\"ERROR: Video directory not found!\")\n",
    "        return [], []\n",
    "\n",
    "    print(f\"Found {len([f for f in os.listdir(video_dir) if f.endswith('.mp4')])} videos\")\n",
    "\n",
    "    # Load and parse JSON\n",
    "    try:\n",
    "        with open(json_path, 'r') as f:\n",
    "            wlasl_data = json.load(f)\n",
    "        print(f\"Loaded WLASL data with {len(wlasl_data)} entries\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load JSON: {e}\")\n",
    "        return [], []\n",
    "\n",
    "    # Build class-video mapping with STRICT quality control\n",
    "    print(\"Building high-quality video mapping...\")\n",
    "    class_videos = {}\n",
    "\n",
    "    for entry in wlasl_data:\n",
    "        gloss = entry.get('gloss', '').strip().lower()\n",
    "        if not gloss or len(gloss) < 2:\n",
    "            continue\n",
    "\n",
    "        instances = entry.get('instances', [])\n",
    "        valid_videos = []\n",
    "\n",
    "        for instance in instances:\n",
    "            video_id = instance.get('video_id')\n",
    "            if video_id:\n",
    "                video_path = os.path.join(video_dir, f\"{video_id}.mp4\")\n",
    "                if os.path.exists(video_path):\n",
    "                    try:\n",
    "                        # STRICT quality checks\n",
    "                        file_size = os.path.getsize(video_path)\n",
    "                        if file_size > 50000:  # Larger files only (50KB+)\n",
    "                            cap = cv2.VideoCapture(video_path)\n",
    "                            if cap.isOpened():\n",
    "                                frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                                fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "                                duration = frame_count / fps if fps > 0 else 0\n",
    "\n",
    "                                # STRICT criteria for limited data\n",
    "                                if (frame_count > 10 and      # At least 10 frames\n",
    "                                    duration > 0.5 and       # At least 0.5 seconds\n",
    "                                    duration < 8 and         # Not too long\n",
    "                                    width >= 320 and         # Decent resolution\n",
    "                                    height >= 240):\n",
    "                                    valid_videos.append(video_path)\n",
    "                            cap.release()\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "        # Only keep classes with sufficient HIGH-QUALITY videos\n",
    "        if len(valid_videos) >= config.min_videos_per_class:\n",
    "            class_videos[gloss] = valid_videos\n",
    "\n",
    "    print(f\"Found {len(class_videos)} classes with sufficient high-quality videos\")\n",
    "\n",
    "    # Sort by video count and select the BEST classes\n",
    "    sorted_classes = sorted(class_videos.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "\n",
    "    print(f\"Top {min(10, len(sorted_classes))} classes by video count:\")\n",
    "    for i, (class_name, videos) in enumerate(sorted_classes[:10]):\n",
    "        print(f\"  {i+1:2d}. {class_name:15}: {len(videos)} videos\")\n",
    "\n",
    "    # Select FEWER classes for better learning\n",
    "    if len(sorted_classes) < config.target_classes:\n",
    "        print(f\"WARNING: Only {len(sorted_classes)} classes available\")\n",
    "        selected_classes = sorted_classes\n",
    "        actual_classes = len(sorted_classes)\n",
    "    else:\n",
    "        selected_classes = sorted_classes[:config.target_classes]\n",
    "        actual_classes = config.target_classes\n",
    "\n",
    "    print(f\"\\nSELECTED {actual_classes} CLASSES FOR FOCUSED TRAINING:\")\n",
    "\n",
    "    # Balanced data allocation\n",
    "    final_paths = []\n",
    "    final_labels = []\n",
    "    class_video_counts = []\n",
    "\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    for i, (class_name, available_videos) in enumerate(selected_classes):\n",
    "        available_count = len(available_videos)\n",
    "\n",
    "        # Use consistent amount per class for balance\n",
    "        videos_to_take = min(config.preferred_videos_per_class, available_count)\n",
    "        videos_to_take = min(videos_to_take, config.max_videos_per_class)\n",
    "\n",
    "        # Randomly select videos\n",
    "        shuffled_videos = available_videos.copy()\n",
    "        np.random.shuffle(shuffled_videos)\n",
    "        selected_videos = shuffled_videos[:videos_to_take]\n",
    "\n",
    "        for video_path in selected_videos:\n",
    "            final_paths.append(video_path)\n",
    "            final_labels.append(class_name)\n",
    "\n",
    "        class_video_counts.append(len(selected_videos))\n",
    "        print(f\"  {i+1:2d}. {class_name:15}: {len(selected_videos):2d}/{available_count:2d} videos selected\")\n",
    "\n",
    "    # Calculate balance statistics\n",
    "    if class_video_counts:\n",
    "        max_count = max(class_video_counts)\n",
    "        min_count = min(class_video_counts)\n",
    "        avg_count = np.mean(class_video_counts)\n",
    "        imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')\n",
    "\n",
    "        print(f\"\\nDATA BALANCE ANALYSIS:\")\n",
    "        print(f\"Videos per class: {min_count} to {max_count} (avg: {avg_count:.1f})\")\n",
    "        print(f\"Imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "        print(f\"Total videos: {len(final_paths)}\")\n",
    "\n",
    "        if imbalance_ratio <= 1.5:\n",
    "            print(\"BALANCE: EXCELLENT - Very well balanced\")\n",
    "        elif imbalance_ratio <= 2.0:\n",
    "            print(\"BALANCE: GOOD - Acceptable for learning\")\n",
    "        else:\n",
    "            print(\"BALANCE: Could be better - will use class weights\")\n",
    "\n",
    "    # Final shuffle\n",
    "    combined = list(zip(final_paths, final_labels))\n",
    "    np.random.shuffle(combined)\n",
    "    final_paths, final_labels = zip(*combined) if combined else ([], [])\n",
    "    final_paths, final_labels = list(final_paths), list(final_labels)\n",
    "\n",
    "    # Final summary\n",
    "    from collections import Counter\n",
    "    label_counts = Counter(final_labels)\n",
    "\n",
    "    print(f\"\\nFINAL SIMPLIFIED DATASET:\")\n",
    "    print(f\"Total videos: {len(final_paths)}\")\n",
    "    print(f\"Total classes: {len(label_counts)}\")\n",
    "    print(\"Final distribution:\")\n",
    "\n",
    "    for label, count in sorted(label_counts.items()):\n",
    "        percentage = (count / len(final_paths)) * 100\n",
    "        print(f\"  {label:15}: {count:2d} videos ({percentage:4.1f}%)\")\n",
    "\n",
    "    print(f\"\\nQUALITY FOCUSED SUMMARY:\")\n",
    "    print(f\"✓ {len(label_counts)} high-quality classes selected\")\n",
    "    print(f\"✓ {len(final_paths)} total videos\")\n",
    "    print(f\"✓ {avg_count:.1f} videos per class on average\")\n",
    "    print(f\"✓ Imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "\n",
    "    if len(final_paths) >= 50:\n",
    "        print(\"✓ SUFFICIENT: Good amount of data for focused learning\")\n",
    "    else:\n",
    "        print(\"⚠ LIMITED: Will need very careful training\")\n",
    "\n",
    "    return final_paths, final_labels\n",
    "\n",
    "# Set the loader function\n",
    "load_dataset = load_simple_dataset\n",
    "\n",
    "print(\"Simplified dataset loader ready!\")\n",
    "print(\"SIMPLIFICATIONS:\")\n",
    "print(\"  - Stricter quality control (50KB+ files, 10+ frames)\")\n",
    "print(\"  - Fewer classes (5) for focused learning\")\n",
    "print(\"  - Balanced allocation per class\")\n",
    "print(\"  - Focus on best available classes\")\n",
    "print(\"  - Quality over quantity approach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified training function ready!\n",
      "SIMPLIFICATIONS:\n",
      "  - Basic normalization (mean/std with clipping)\n",
      "  - Standard categorical crossentropy loss\n",
      "  - Simple class weighting\n",
      "  - Minimal callbacks\n",
      "  - Focus on preventing class collapse\n",
      "  - Strong regularization to prevent overfitting\n"
     ]
    }
   ],
   "source": [
    "# @title 6: Simplified Training Function for Limited Data\n",
    "def train_simple_model(config):\n",
    "    \"\"\"Simplified training function optimized for limited data\"\"\"\n",
    "\n",
    "    set_seeds(SEED)\n",
    "    print(\"Starting SIMPLIFIED ASL model training...\")\n",
    "    print(\"GOAL: Prevent class collapse with minimal overfitting\")\n",
    "    print(\"STRATEGY: Small model + Strong regularization + Quality data\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Load simplified dataset\n",
    "    video_paths, labels = load_dataset(config)\n",
    "    if not video_paths:\n",
    "        print(\"ERROR: No videos loaded!\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    print(f\"Processing {len(video_paths)} videos from simplified dataset...\")\n",
    "\n",
    "    # Simple feature extraction with progress tracking\n",
    "    X_features = []\n",
    "    y_labels = []\n",
    "    valid_count = 0\n",
    "    failed_count = 0\n",
    "\n",
    "    for i, (video_path, label) in enumerate(zip(video_paths, labels)):\n",
    "        if i % 10 == 0:\n",
    "            progress_pct = (i / len(video_paths)) * 100\n",
    "            print(f\"  Progress: {progress_pct:.1f}% ({i+1}/{len(video_paths)}) - Valid: {valid_count}, Failed: {failed_count}\")\n",
    "\n",
    "        try:\n",
    "            features = extract_video_features(\n",
    "                video_path,\n",
    "                sequence_length=config.sequence_length,\n",
    "                min_confidence=config.min_detection_confidence\n",
    "            )\n",
    "\n",
    "            if features is not None and features.size > 0:\n",
    "                # Simple quality check\n",
    "                non_zero_ratio = np.count_nonzero(features) / features.size\n",
    "                \n",
    "                if non_zero_ratio > 0.05:  # At least 5% non-zero\n",
    "                    X_features.append(features)\n",
    "                    y_labels.append(label)\n",
    "                    valid_count += 1\n",
    "                else:\n",
    "                    failed_count += 1\n",
    "            else:\n",
    "                failed_count += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            failed_count += 1\n",
    "            if i < 3:  # Show first few errors\n",
    "                print(f\"    Error processing {video_path}: {e}\")\n",
    "\n",
    "    print(f\"\\nSimple feature extraction completed:\")\n",
    "    print(f\"Valid: {valid_count}, Failed: {failed_count}\")\n",
    "\n",
    "    if not X_features:\n",
    "        print(\"ERROR: No valid features extracted!\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    X = np.array(X_features, dtype=np.float32)\n",
    "    del X_features\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"Final dataset shape: {X.shape}\")\n",
    "\n",
    "    # Simple normalization\n",
    "    print(\"Applying simple normalization...\")\n",
    "    X_flat = X.reshape(-1, X.shape[-1])\n",
    "    \n",
    "    # Standard scaling with clipping\n",
    "    mean = np.mean(X_flat, axis=0)\n",
    "    std = np.std(X_flat, axis=0)\n",
    "    std = np.where(std > 1e-8, std, 1.0)  # Avoid division by zero\n",
    "    \n",
    "    X_flat = (X_flat - mean) / std\n",
    "    X_flat = np.clip(X_flat, -3, 3)  # Clip outliers\n",
    "    \n",
    "    X = X_flat.reshape(X.shape)\n",
    "    del X_flat\n",
    "    gc.collect()\n",
    "\n",
    "    # Label encoding\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y_labels)\n",
    "    num_classes = len(le.classes_)\n",
    "\n",
    "    print(f\"Classes: {num_classes}\")\n",
    "    unique_labels, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "    print(\"Class distribution:\")\n",
    "    for class_idx, count in zip(unique_labels, counts):\n",
    "        percentage = (count / len(y)) * 100\n",
    "        print(f\"  {le.classes_[class_idx]:15}: {count:2d} samples ({percentage:4.1f}%)\")\n",
    "\n",
    "    # Simple train/validation split\n",
    "    try:\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y,\n",
    "            test_size=config.validation_split,\n",
    "            random_state=SEED,\n",
    "            stratify=y\n",
    "        )\n",
    "        print(f\"Stratified split: {len(X_train)} train, {len(X_val)} validation\")\n",
    "    except ValueError:\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y,\n",
    "            test_size=config.validation_split,\n",
    "            random_state=SEED,\n",
    "            shuffle=True\n",
    "        )\n",
    "        print(f\"Random split: {len(X_train)} train, {len(X_val)} validation\")\n",
    "\n",
    "    # Create minimal model\n",
    "    print(\"Creating minimal model...\")\n",
    "    model = create_model(config, num_classes)\n",
    "\n",
    "    # Simple optimizer\n",
    "    optimizer = Adam(\n",
    "        learning_rate=config.learning_rate,\n",
    "        clipnorm=config.gradient_clip_norm\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    total_params = model.count_params()\n",
    "    print(f\"Model parameters: {total_params:,} total\")\n",
    "\n",
    "    # Simple callbacks\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\n",
    "            f\"/content/{config.model_name}_best.keras\",\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1,\n",
    "            mode='max'\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=config.early_stopping_patience,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1,\n",
    "            min_delta=0.001\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=config.lr_reduction_factor,\n",
    "            patience=config.lr_reduction_patience,\n",
    "            min_lr=config.min_lr,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Simple class weighting\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    \n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "    print(f\"Class weights:\")\n",
    "    for class_idx, weight in class_weight_dict.items():\n",
    "        class_name = le.classes_[class_idx]\n",
    "        print(f\"  {class_name:15}: {weight:6.3f}\")\n",
    "\n",
    "    print(f\"\\nStarting SIMPLE {num_classes}-class training:\")\n",
    "    print(f\"  Dataset: {len(video_paths)} videos, {num_classes} classes\")\n",
    "    print(f\"  Model: {total_params:,} parameters (minimal)\")\n",
    "    print(f\"  Strategy: Strong regularization + Simple architecture\")\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=config.num_epochs,\n",
    "        batch_size=config.batch_size,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weight_dict,\n",
    "        verbose=1,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Plot results\n",
    "    plot_training_results(history, config.model_name)\n",
    "\n",
    "    # Simple performance analysis\n",
    "    print(\"\\nSIMPLE PERFORMANCE ANALYSIS:\")\n",
    "    try:\n",
    "        from sklearn.metrics import classification_report\n",
    "\n",
    "        y_pred = model.predict(X_val, verbose=0)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        print(\"\\nPer-class performance:\")\n",
    "        learned_classes = 0\n",
    "        collapsed_classes = 0\n",
    "\n",
    "        for class_idx in range(num_classes):\n",
    "            class_name = le.classes_[class_idx]\n",
    "            \n",
    "            # Calculate simple metrics\n",
    "            true_positives = np.sum((y_val == class_idx) & (y_pred_classes == class_idx))\n",
    "            total_true = np.sum(y_val == class_idx)\n",
    "            total_pred = np.sum(y_pred_classes == class_idx)\n",
    "            \n",
    "            recall = true_positives / total_true if total_true > 0 else 0\n",
    "            precision = true_positives / total_pred if total_pred > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            if f1 > 0.1:  # Learning threshold\n",
    "                learned_classes += 1\n",
    "                status = \"LEARNED ✓\"\n",
    "            else:\n",
    "                collapsed_classes += 1\n",
    "                status = \"COLLAPSED ✗\"\n",
    "            \n",
    "            print(f\"  {class_name:15}: F1={f1:.3f}, P={precision:.3f}, R={recall:.3f} ({status})\")\n",
    "\n",
    "        learning_ratio = learned_classes / num_classes\n",
    "        print(f\"\\nCLASS COLLAPSE ANALYSIS:\")\n",
    "        print(f\"Learned classes: {learned_classes}/{num_classes} ({learning_ratio*100:.1f}%)\")\n",
    "        print(f\"Collapsed classes: {collapsed_classes}/{num_classes} ({(1-learning_ratio)*100:.1f}%)\")\n",
    "\n",
    "        if learning_ratio >= 0.8:\n",
    "            print(\"RESULT: EXCELLENT - Class collapse mostly prevented! ✓✓✓\")\n",
    "        elif learning_ratio >= 0.6:\n",
    "            print(\"RESULT: GOOD - Most classes learning ✓✓\")\n",
    "        elif learning_ratio >= 0.4:\n",
    "            print(\"RESULT: MODERATE - Some improvement ✓\")\n",
    "        else:\n",
    "            print(\"RESULT: POOR - Class collapse persists ✗\")\n",
    "\n",
    "        # Overfitting analysis\n",
    "        val_accuracies = history.history.get('val_accuracy', [])\n",
    "        train_accuracies = history.history.get('accuracy', [])\n",
    "        \n",
    "        if val_accuracies and train_accuracies:\n",
    "            best_val_acc = max(val_accuracies)\n",
    "            final_train_acc = train_accuracies[-1]\n",
    "            final_val_acc = val_accuracies[-1]\n",
    "            overfitting_gap = final_train_acc - final_val_acc\n",
    "            \n",
    "            print(f\"\\nOVERFITTING ANALYSIS:\")\n",
    "            print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "            print(f\"Final train/val gap: {overfitting_gap:.4f}\")\n",
    "            \n",
    "            if overfitting_gap < 0.1:\n",
    "                print(\"OVERFITTING: Minimal - excellent generalization ✓\")\n",
    "            elif overfitting_gap < 0.2:\n",
    "                print(\"OVERFITTING: Low - acceptable generalization ✓\")\n",
    "            else:\n",
    "                print(\"OVERFITTING: High - need more regularization ✗\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not complete analysis: {e}\")\n",
    "\n",
    "    return model, le, history, X_val, y_val\n",
    "\n",
    "# Set as main training function\n",
    "train_model = train_simple_model\n",
    "\n",
    "print(\"Simplified training function ready!\")\n",
    "print(\"SIMPLIFICATIONS:\")\n",
    "print(\"  - Basic normalization (mean/std with clipping)\")\n",
    "print(\"  - Standard categorical crossentropy loss\")\n",
    "print(\"  - Simple class weighting\")\n",
    "print(\"  - Minimal callbacks\")\n",
    "print(\"  - Focus on preventing class collapse\")\n",
    "print(\"  - Strong regularization to prevent overfitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SIMPLIFIED ASL Recognition Training...\n",
      "PRIMARY MISSION: Prevent class collapse with minimal model\n",
      "STRATEGY: 5 classes + Tiny model + Heavy regularization\n",
      "============================================================\n",
      "Starting SIMPLIFIED ASL model training...\n",
      "GOAL: Prevent class collapse with minimal overfitting\n",
      "STRATEGY: Small model + Strong regularization + Quality data\n",
      "============================================================\n",
      "Loading SIMPLIFIED dataset from: ./risangbaskoro/wlasl-processed/versions/5\n",
      "Strategy: Quality over quantity - fewer classes, better data\n",
      "Target: 20 classes with 8+ videos each\n",
      "Found 11980 videos\n",
      "Loaded WLASL data with 2000 entries\n",
      "Building high-quality video mapping...\n",
      "Found 110 classes with sufficient high-quality videos\n",
      "Top 10 classes by video count:\n",
      "   1. thin           : 13 videos\n",
      "   2. cool           : 13 videos\n",
      "   3. who            : 12 videos\n",
      "   4. computer       : 11 videos\n",
      "   5. before         : 11 videos\n",
      "   6. candy          : 11 videos\n",
      "   7. cousin         : 11 videos\n",
      "   8. later          : 11 videos\n",
      "   9. man            : 11 videos\n",
      "  10. tall           : 11 videos\n",
      "\n",
      "SELECTED 20 CLASSES FOR FOCUSED TRAINING:\n",
      "   1. thin           : 13/13 videos selected\n",
      "   2. cool           : 13/13 videos selected\n",
      "   3. who            : 12/12 videos selected\n",
      "   4. computer       : 11/11 videos selected\n",
      "   5. before         : 11/11 videos selected\n",
      "   6. candy          : 11/11 videos selected\n",
      "   7. cousin         : 11/11 videos selected\n",
      "   8. later          : 11/11 videos selected\n",
      "   9. man            : 11/11 videos selected\n",
      "  10. tall           : 11/11 videos selected\n",
      "  11. drink          : 10/10 videos selected\n",
      "  12. what           : 10/10 videos selected\n",
      "  13. bed            : 10/10 videos selected\n",
      "  14. apple          : 10/10 videos selected\n",
      "  15. corn           : 10/10 videos selected\n",
      "  16. dark           : 10/10 videos selected\n",
      "  17. short          : 10/10 videos selected\n",
      "  18. basketball     : 10/10 videos selected\n",
      "  19. brother        : 10/10 videos selected\n",
      "  20. example        : 10/10 videos selected\n",
      "\n",
      "DATA BALANCE ANALYSIS:\n",
      "Videos per class: 10 to 13 (avg: 10.8)\n",
      "Imbalance ratio: 1.30\n",
      "Total videos: 215\n",
      "BALANCE: EXCELLENT - Very well balanced\n",
      "\n",
      "FINAL SIMPLIFIED DATASET:\n",
      "Total videos: 215\n",
      "Total classes: 20\n",
      "Final distribution:\n",
      "  apple          : 10 videos ( 4.7%)\n",
      "  basketball     : 10 videos ( 4.7%)\n",
      "  bed            : 10 videos ( 4.7%)\n",
      "  before         : 11 videos ( 5.1%)\n",
      "  brother        : 10 videos ( 4.7%)\n",
      "  candy          : 11 videos ( 5.1%)\n",
      "  computer       : 11 videos ( 5.1%)\n",
      "  cool           : 13 videos ( 6.0%)\n",
      "  corn           : 10 videos ( 4.7%)\n",
      "  cousin         : 11 videos ( 5.1%)\n",
      "  dark           : 10 videos ( 4.7%)\n",
      "  drink          : 10 videos ( 4.7%)\n",
      "  example        : 10 videos ( 4.7%)\n",
      "  later          : 11 videos ( 5.1%)\n",
      "  man            : 11 videos ( 5.1%)\n",
      "  short          : 10 videos ( 4.7%)\n",
      "  tall           : 11 videos ( 5.1%)\n",
      "  thin           : 13 videos ( 6.0%)\n",
      "  what           : 10 videos ( 4.7%)\n",
      "  who            : 12 videos ( 5.6%)\n",
      "\n",
      "QUALITY FOCUSED SUMMARY:\n",
      "✓ 20 high-quality classes selected\n",
      "✓ 215 total videos\n",
      "✓ 10.8 videos per class on average\n",
      "✓ Imbalance ratio: 1.30\n",
      "✓ SUFFICIENT: Good amount of data for focused learning\n",
      "Processing 215 videos from simplified dataset...\n",
      "  Progress: 0.0% (1/215) - Valid: 0, Failed: 0\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "  Progress: 4.7% (11/215) - Valid: 10, Failed: 0\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "  Progress: 9.3% (21/215) - Valid: 20, Failed: 0\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "  Progress: 14.0% (31/215) - Valid: 30, Failed: 0\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "  Progress: 18.6% (41/215) - Valid: 40, Failed: 0\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "  Progress: 23.3% (51/215) - Valid: 50, Failed: 0\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "  Progress: 27.9% (61/215) - Valid: 60, Failed: 0\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "  Progress: 32.6% (71/215) - Valid: 70, Failed: 0\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "  Progress: 37.2% (81/215) - Valid: 80, Failed: 0\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "  Progress: 41.9% (91/215) - Valid: 90, Failed: 0\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "  Progress: 46.5% (101/215) - Valid: 100, Failed: 0\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "  Progress: 51.2% (111/215) - Valid: 110, Failed: 0\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "  Progress: 55.8% (121/215) - Valid: 120, Failed: 0\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "  Progress: 60.5% (131/215) - Valid: 130, Failed: 0\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "  Progress: 65.1% (141/215) - Valid: 139, Failed: 1\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n",
      "Simple MediaPipe extractor ready (confidence=0.5)\n"
     ]
    }
   ],
   "source": [
    "# @title 7: Run Simplified Training (Fix Class Collapse)\n",
    "print(\"Starting SIMPLIFIED ASL Recognition Training...\")\n",
    "print(\"PRIMARY MISSION: Prevent class collapse with minimal model\")\n",
    "print(\"STRATEGY: 5 classes + Tiny model + Heavy regularization\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Clear memory and reset\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "set_seeds(SEED)\n",
    "\n",
    "# Initialize variables to store training results\n",
    "trained_model = None\n",
    "trained_label_encoder = None\n",
    "training_history = None\n",
    "validation_X = None\n",
    "validation_y = None\n",
    "\n",
    "try:\n",
    "    # Run simplified training\n",
    "    results = train_model(config)\n",
    "\n",
    "    if results and len(results) == 5:\n",
    "        trained_model, trained_label_encoder, training_history, validation_X, validation_y = results\n",
    "\n",
    "        if training_history and trained_model and trained_label_encoder:\n",
    "            val_accuracies = training_history.history.get('val_accuracy', [])\n",
    "            train_accuracies = training_history.history.get('accuracy', [])\n",
    "\n",
    "            if val_accuracies and train_accuracies:\n",
    "                best_val_acc = max(val_accuracies)\n",
    "                best_epoch = np.argmax(val_accuracies) + 1\n",
    "                final_val_acc = val_accuracies[-1]\n",
    "                final_train_acc = train_accuracies[-1]\n",
    "                overfitting_gap = final_train_acc - final_val_acc\n",
    "                epochs_completed = len(training_history.history['loss'])\n",
    "\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(\"SIMPLIFIED TRAINING RESULTS\")\n",
    "                print(\"=\"*60)\n",
    "                print(f\"Best Validation Accuracy: {best_val_acc:.4f} (Epoch {best_epoch})\")\n",
    "                print(f\"Final Train/Val: {final_train_acc:.4f}/{final_val_acc:.4f}\")\n",
    "                print(f\"Overfitting Gap: {overfitting_gap:.4f}\")\n",
    "                print(f\"Epochs Completed: {epochs_completed}/{config.num_epochs}\")\n",
    "\n",
    "                # Performance assessment\n",
    "                num_classes = len(trained_label_encoder.classes_)\n",
    "                random_baseline = 1.0 / num_classes\n",
    "                improvement = (best_val_acc - random_baseline) / random_baseline * 100\n",
    "\n",
    "                print(f\"\\nPerformance Analysis:\")\n",
    "                print(f\"Random baseline ({num_classes} classes): {random_baseline:.1%}\")\n",
    "                print(f\"Best validation: {best_val_acc:.1%}\")\n",
    "                print(f\"Improvement over random: {improvement:.1f}%\")\n",
    "\n",
    "                if best_val_acc > 0.60:\n",
    "                    print(\"STATUS: EXCELLENT - Great performance!\")\n",
    "                elif best_val_acc > 0.40:\n",
    "                    print(\"STATUS: GOOD - Solid learning\")\n",
    "                elif best_val_acc > random_baseline * 1.5:\n",
    "                    print(\"STATUS: LEARNING - Better than random\")\n",
    "                else:\n",
    "                    print(\"STATUS: POOR - Still struggling\")\n",
    "\n",
    "                # Overfitting assessment\n",
    "                if overfitting_gap < 0.05:\n",
    "                    print(\"OVERFITTING: Minimal - excellent generalization\")\n",
    "                elif overfitting_gap < 0.15:\n",
    "                    print(\"OVERFITTING: Low - good generalization\")\n",
    "                elif overfitting_gap < 0.25:\n",
    "                    print(\"OVERFITTING: Moderate - acceptable\")\n",
    "                else:\n",
    "                    print(\"OVERFITTING: High - may need more regularization\")\n",
    "\n",
    "                # Quick class collapse check\n",
    "                try:\n",
    "                    y_pred = trained_model.predict(validation_X, verbose=0)\n",
    "                    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "                    \n",
    "                    # Count classes that have any correct predictions\n",
    "                    classes_with_predictions = len(np.unique(y_pred_classes))\n",
    "                    classes_with_correct_predictions = 0\n",
    "                    \n",
    "                    for class_idx in range(num_classes):\n",
    "                        correct_predictions = np.sum((validation_y == class_idx) & (y_pred_classes == class_idx))\n",
    "                        if correct_predictions > 0:\n",
    "                            classes_with_correct_predictions += 1\n",
    "                    \n",
    "                    prediction_diversity = classes_with_predictions / num_classes\n",
    "                    success_diversity = classes_with_correct_predictions / num_classes\n",
    "                    \n",
    "                    print(f\"\\nCLASS COLLAPSE CHECK:\")\n",
    "                    print(f\"Classes predicted: {classes_with_predictions}/{num_classes} ({prediction_diversity:.1%})\")\n",
    "                    print(f\"Classes with correct predictions: {classes_with_correct_predictions}/{num_classes} ({success_diversity:.1%})\")\n",
    "                    \n",
    "                    if success_diversity >= 0.8:\n",
    "                        print(\"RESULT: CLASS COLLAPSE PREVENTED! Success!\")\n",
    "                    elif success_diversity >= 0.6:\n",
    "                        print(\"RESULT: MAJOR IMPROVEMENT - Most classes learning\")\n",
    "                    elif success_diversity >= 0.4:\n",
    "                        print(\"RESULT: SOME IMPROVEMENT - Partial success\")\n",
    "                    else:\n",
    "                        print(\"RESULT: CLASS COLLAPSE PERSISTS - Need different approach\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not check class collapse: {e}\")\n",
    "\n",
    "                # Save model if decent results\n",
    "                if best_val_acc > random_baseline * 1.2:  # At least 20% better than random\n",
    "                    try:\n",
    "                        trained_model.save(f\"/content/{config.model_name}_best.keras\")\n",
    "                        print(f\"\\nModel saved: {config.model_name}_best.keras\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Could not save model: {e}\")\n",
    "\n",
    "                # Recommendations\n",
    "                print(f\"\\nNEXT STEPS:\")\n",
    "                if success_diversity >= 0.6 and overfitting_gap < 0.2:\n",
    "                    print(\"1. Success! Try gradually adding more classes\")\n",
    "                    print(\"2. Experiment with slightly larger model\")\n",
    "                    print(\"3. Try longer sequences for more context\")\n",
    "                elif overfitting_gap > 0.3:\n",
    "                    print(\"1. Increase dropout even more (0.8+)\")\n",
    "                    print(\"2. Reduce model size further\")\n",
    "                    print(\"3. Add more L2 regularization\")\n",
    "                    print(\"4. Collect more training data\")\n",
    "                elif success_diversity < 0.4:\n",
    "                    print(\"1. Check feature extraction quality\")\n",
    "                    print(\"2. Try different model architectures\")\n",
    "                    print(\"3. Consider simpler classifiers (SVM, Random Forest)\")\n",
    "                    print(\"4. Investigate data quality issues\")\n",
    "                else:\n",
    "                    print(\"1. Good progress! Fine-tune hyperparameters\")\n",
    "                    print(\"2. Try ensemble methods\")\n",
    "                    print(\"3. Experiment with data augmentation\")\n",
    "\n",
    "                print(f\"\\nTRAINED MODEL STORED IN VARIABLES:\")\n",
    "                print(f\"- trained_model: Keras model ready for analysis\")\n",
    "                print(f\"- trained_label_encoder: Label encoder for classes\")\n",
    "                print(f\"- training_history: Training history object\")\n",
    "                print(f\"- validation_X: Validation features\")\n",
    "                print(f\"- validation_y: Validation labels\")\n",
    "\n",
    "            else:\n",
    "                print(\"ERROR: No training metrics recorded\")\n",
    "        else:\n",
    "            print(\"ERROR: Training returned incomplete results\")\n",
    "    else:\n",
    "        print(\"ERROR: Training failed completely\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"TRAINING ERROR: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "    print(f\"\\nTROUBLESHOOTING:\")\n",
    "    print(f\"1. Check dataset path and video accessibility\")\n",
    "    print(f\"2. Verify MediaPipe installation\")\n",
    "    print(f\"3. Try reducing classes to 3-4\")\n",
    "    print(f\"4. Check if videos contain visible hands\")\n",
    "    print(f\"5. Restart runtime if memory issues\")\n",
    "\n",
    "finally:\n",
    "    # Clean up\n",
    "    gc.collect()\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Simplified training completed.\")\n",
    "    print(\"Check results above to see if class collapse was prevented!\")\n",
    "    print(\"The simplified approach should show better class diversity.\")\n",
    "    \n",
    "    if trained_model is not None:\n",
    "        print(\"SUCCESS: Model variables are ready for analysis in code cell 8!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found trained model from code cell 7. Running analysis...\n",
      "ANALYZING AND SAVING TRAINED MODEL\n",
      "============================================================\n",
      "\n",
      "1. MODEL PERFORMANCE ANALYSIS:\n",
      "----------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      before       0.00      0.00      0.00         2\n",
      "       candy       1.00      0.50      0.67         2\n",
      "    computer       0.50      0.50      0.50         2\n",
      "        cool       0.33      0.33      0.33         3\n",
      "      cousin       0.00      0.00      0.00         2\n",
      "       later       0.00      0.00      0.00         2\n",
      "         man       0.33      0.50      0.40         2\n",
      "        tall       0.00      0.00      0.00         2\n",
      "        thin       1.00      0.33      0.50         3\n",
      "         who       0.12      0.33      0.18         3\n",
      "\n",
      "    accuracy                           0.26        23\n",
      "   macro avg       0.33      0.25      0.26        23\n",
      "weighted avg       0.35      0.26      0.27        23\n",
      "\n",
      "\n",
      "2. CONFUSION MATRIX:\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-class Accuracies:\n",
      "  before         : 0.0000\n",
      "  candy          : 0.5000\n",
      "  computer       : 0.5000\n",
      "  cool           : 0.3333\n",
      "  cousin         : 0.0000\n",
      "  later          : 0.0000\n",
      "  man            : 0.5000\n",
      "  tall           : 0.0000\n",
      "  thin           : 0.3333\n",
      "  who            : 0.3333\n",
      "\n",
      "3. SAVING MODEL:\n",
      "----------------------------------------\n",
      "✅ Model saved to ./models/simple_asl_10_classes_final.keras\n",
      "✅ Labels saved to ./models/simple_asl_10_classes_final_labels.pkl\n",
      "✅ Config saved to ./models/simple_asl_10_classes_final_config.json\n",
      "\n",
      "📦 Complete model package saved!\n",
      "\n",
      "4. MODEL SUMMARY:\n",
      "----------------------------------------\n",
      "Model architecture: Minimal_ASL_Model_10_classes\n",
      "Total parameters: 23,498\n",
      "Number of classes: 10\n",
      "Classes: ['before', 'candy', 'computer', 'cool', 'cousin', 'later', 'man', 'tall', 'thin', 'who']\n",
      "Validation samples: 23\n",
      "\n",
      "5. SAMPLE PREDICTIONS:\n",
      "----------------------------------------\n",
      "  Sample 1: True='cool' | Pred='cool' | Conf=0.179 ✓\n",
      "  Sample 2: True='cool' | Pred='computer' | Conf=0.351 ✗\n",
      "  Sample 3: True='man' | Pred='cool' | Conf=0.191 ✗\n",
      "  Sample 4: True='candy' | Pred='who' | Conf=0.196 ✗\n",
      "  Sample 5: True='cousin' | Pred='who' | Conf=0.250 ✗\n",
      "\n",
      "============================================================\n",
      "MODEL ANALYSIS AND SAVING COMPLETED SUCCESSFULLY!\n",
      "Your model is now saved and ready for use!\n"
     ]
    }
   ],
   "source": [
    "# @title 8: Analyze and Save the Trained Model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "def analyze_and_save_model(model, X_val, y_val, label_encoder, config):\n",
    "    \"\"\"Combined function to analyze model performance and save all components\"\"\"\n",
    "    \n",
    "    print(\"ANALYZING AND SAVING TRAINED MODEL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. PERFORMANCE ANALYSIS\n",
    "    print(\"\\n1. MODEL PERFORMANCE ANALYSIS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_val, batch_size=8, verbose=0)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # Classification report\n",
    "    class_names = label_encoder.classes_\n",
    "    try:\n",
    "        report = classification_report(y_val, y_pred_classes, target_names=class_names)\n",
    "        print(report)\n",
    "    except:\n",
    "        print(\"Manual per-class analysis:\")\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            mask_true = y_val == i\n",
    "            mask_pred = y_pred_classes == i\n",
    "            \n",
    "            tp = np.sum(mask_true & mask_pred)\n",
    "            fp = np.sum(~mask_true & mask_pred) \n",
    "            fn = np.sum(mask_true & ~mask_pred)\n",
    "            \n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            print(f\"  {class_name:15}: P={precision:.3f}, R={recall:.3f}, F1={f1:.3f}\")\n",
    "    \n",
    "    # 2. CONFUSION MATRIX\n",
    "    print(f\"\\n2. CONFUSION MATRIX:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    cm = confusion_matrix(y_val, y_pred_classes)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix - Simplified Model')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
    "    print(f\"\\nPer-class Accuracies:\")\n",
    "    for i, (class_name, acc) in enumerate(zip(class_names, class_accuracies)):\n",
    "        if not np.isnan(acc):\n",
    "            print(f\"  {class_name:15}: {acc:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {class_name:15}: No samples\")\n",
    "    \n",
    "    # 3. SAVE MODEL COMPONENTS\n",
    "    print(f\"\\n3. SAVING MODEL:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    model_path = f\"./models/{config.model_name}_final\"\n",
    "    \n",
    "    try:\n",
    "        # Save model\n",
    "        model.save(f\"{model_path}.keras\")\n",
    "        print(f\"✅ Model saved to {model_path}.keras\")\n",
    "        \n",
    "        # Save label encoder\n",
    "        joblib.dump(label_encoder, f\"{model_path}_labels.pkl\")\n",
    "        print(f\"✅ Labels saved to {model_path}_labels.pkl\")\n",
    "        \n",
    "        # Save config\n",
    "        config_dict = {\n",
    "            'sequence_length': config.sequence_length,\n",
    "            'min_detection_confidence': config.min_detection_confidence,\n",
    "            'classes': list(label_encoder.classes_),\n",
    "            'num_classes': len(label_encoder.classes_)\n",
    "        }\n",
    "        \n",
    "        with open(f\"{model_path}_config.json\", 'w') as f:\n",
    "            json.dump(config_dict, f, indent=2)\n",
    "        print(f\"✅ Config saved to {model_path}_config.json\")\n",
    "        \n",
    "        print(f\"\\n📦 Complete model package saved!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving model: {e}\")\n",
    "    \n",
    "    # 4. SUMMARY AND SAMPLE PREDICTIONS\n",
    "    print(f\"\\n4. MODEL SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Model architecture: {model.name}\")\n",
    "    print(f\"Total parameters: {model.count_params():,}\")\n",
    "    print(f\"Number of classes: {len(label_encoder.classes_)}\")\n",
    "    print(f\"Classes: {list(label_encoder.classes_)}\")\n",
    "    print(f\"Validation samples: {len(X_val)}\")\n",
    "    \n",
    "    # Sample predictions\n",
    "    if len(X_val) > 0:\n",
    "        print(f\"\\n5. SAMPLE PREDICTIONS:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        sample_size = min(5, len(X_val))\n",
    "        for i in range(sample_size):\n",
    "            true_label = label_encoder.classes_[y_val[i]]\n",
    "            pred_label = label_encoder.classes_[y_pred_classes[i]]\n",
    "            confidence = y_pred[i][y_pred_classes[i]]\n",
    "            \n",
    "            status = \"✓\" if true_label == pred_label else \"✗\"\n",
    "            print(f\"  Sample {i+1}: True='{true_label}' | Pred='{pred_label}' | Conf={confidence:.3f} {status}\")\n",
    "    \n",
    "    return y_pred, y_pred_classes\n",
    "\n",
    "# RUN ANALYSIS AND SAVING\n",
    "if trained_model is not None and trained_label_encoder is not None:\n",
    "    print(\"Found trained model from code cell 7. Running analysis...\")\n",
    "    \n",
    "    try:\n",
    "        predictions, predicted_classes = analyze_and_save_model(\n",
    "            trained_model, \n",
    "            validation_X, \n",
    "            validation_y, \n",
    "            trained_label_encoder, \n",
    "            config\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"MODEL ANALYSIS AND SAVING COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"Your model is now saved and ready for use!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during analysis and saving: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "else:\n",
    "    print(\"ERROR: No trained model found!\")\n",
    "    print(\"Please run code cell 7 first to train the model.\")\n",
    "    print(\"Required variables: trained_model, trained_label_encoder, validation_X, validation_y\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.23 ('asl_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88aa817c7a639a7aeb80fa727a7a1e07e1a6ee98728808c1c7c6d1da00bea67a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
